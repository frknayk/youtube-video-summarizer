{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcript\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import os\n",
    "# Summarization\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transcript Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_transcript(video_url):\n",
    "    try:\n",
    "        # Extract the video ID from the URL\n",
    "        video_id = video_url.split(\"v=\")[1]\n",
    "        # Fetch the transcript for the video\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        # Process the transcript data\n",
    "        text_transcript = \"\\n\".join([entry['text'] for entry in transcript])\n",
    "        return text_transcript\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "import re \n",
    "def clean_transcript(transcript):\n",
    "    # Remove non-speech elements (e.g., laughter, background noises)\n",
    "    transcript = re.sub(r'\\[.*?\\]', '', transcript)\n",
    "\n",
    "    # Correct spelling and grammar (you can use libraries like NLTK or spaCy for this)\n",
    "    # Example:\n",
    "    # import nltk\n",
    "    # transcript = ' '.join(nltk.word_tokenize(transcript))\n",
    "\n",
    "    # Normalize punctuation and formatting\n",
    "    transcript = transcript.replace('\\n', ' ')  # Remove line breaks\n",
    "    transcript = re.sub(r'\\s+', ' ', transcript)  # Remove extra whitespaces\n",
    "\n",
    "    # Remove timestamps and annotations\n",
    "    transcript = re.sub(r'\\[\\d+:\\d+:\\d+\\]', '', transcript)\n",
    "\n",
    "    # Handle speaker identification (if present)\n",
    "    # Example: transcript = re.sub(r'Speaker\\d+:', '', transcript)\n",
    "\n",
    "    # Remove filler words and phrases\n",
    "    filler_words = ['like', 'you know', 'sort of']  # Add more as needed\n",
    "    for word in filler_words:\n",
    "        transcript = transcript.replace(word, '')\n",
    "    \n",
    "    # Replace common contractions with their expanded forms\n",
    "    transcript = transcript.replace(\"won't\", \"will not\")\n",
    "    transcript = transcript.replace(\"can't\", \"cannot\")\n",
    "    transcript = transcript.replace(\"n't\", \" not\")\n",
    "    transcript = transcript.replace(\"'ll\", \" will\")\n",
    "    transcript = transcript.replace(\"'ve\", \" have\")\n",
    "    transcript = transcript.replace(\"'re\", \" are\")\n",
    "    transcript = transcript.replace(\"'d\", \" would\")\n",
    "    transcript = transcript.replace(\"'s\", \" is\")\n",
    "\n",
    "    return transcript.strip()  # Trim leading/trailing whitespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Summarization LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(llama_pipeline, system_prompt, text):\n",
    "    \"\"\"\n",
    "    It is not a good practice to load the model again and again,\n",
    "    but for the sake of simlicity for demo, let's keep as it is\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Format the input text with special tokens for the model\n",
    "    text = f\"\"\"\n",
    "    <s>[INST] <<SYS>>\n",
    "    {system_prompt}\n",
    "    <</SYS>>\n",
    "    {text}[/INST]\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequences using the pipeline with specified parameters\n",
    "    sequences = llama_pipeline(\n",
    "        text,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=32000\n",
    "    )\n",
    "\n",
    "    # Extract the generated text from the sequences\n",
    "    generated_text = sequences[0][\"generated_text\"]\n",
    "    # Trim the generated text to remove the instruction part\n",
    "    generated_text = generated_text[generated_text.find('[/INST]')+len('[/INST]'):]\n",
    "\n",
    "    # Return the processed generated text\n",
    "    return generated_text\n",
    "\n",
    "def summarize(text, llama_pipeline):\n",
    "    # Define the maximum input length for each iteration of summarization\n",
    "    input_len = 10000\n",
    "\n",
    "    # Start an infinite loop to repeatedly summarize the text\n",
    "    while True:\n",
    "        # Print the current length of the text\n",
    "        print(len(text))\n",
    "        # Call the chat function to summarize the text. Only the first 'input_len' characters are considered for summarization\n",
    "        summary = chat(llama_pipeline, \"\", \"Summarize the following: \" + text[0:input_len])\n",
    "\n",
    "        if len(text) < input_len:\n",
    "            return summary\n",
    "        \n",
    "        # Concatenate the current summary with the remaining part of the text for the next iteration\n",
    "        text = summary + \" \" + text[input_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67f6855f92c4c13ad1db92a26adc08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Define the model name to be used for the chat function\n",
    "    model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    pipeline_llama2 = pipeline(\n",
    "        \"text-generation\", #task\n",
    "        model=model_name,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        # max_length=max_token_length,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = clean_transcript(fetch_transcript(\"https://www.youtube.com/watch?v=5t1vTLU7s40\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YannLecun_LexPodcast.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11819\n",
      "2688\n",
      "\n",
      "     The speaker argues that the conventional wisdom on success, such as waking up early, removing distractions, and having goals, is overrated and not the key to success. Instead, he suggests that being a correct contrarian and having unpopular beliefs is more important. He cites examples of successful people throughout history who had contrarian ideas that were initially ridiculed but ultimately proved to be correct. The speaker also acknowledges that executing on those ideas is important, but it's not sufficient on its own. He suggests that finding one correct contrarian idea can have a significant impact on a person's career, more than any other factor. However, he also notes that extreme success can have negative consequences, such as a lack of validation and approval from others, and that it may not improve relationships that don't need improvement.\n",
      "\n",
      "The speaker emphasizes that being correctly contrarian is not a guarantee of success, and that most contrarian beliefs are contrarian for a reason, because they are wrong. He notes that many people have tried these ideas and failed miserably, and have spent the rest of their lives wondering what they were thinking. The speaker suggests that success amplifies who you already are and how you already feel, so people who are angry and depressed may become even angrier and more depressed with success, while those with great relationships may see their relationships improve even more.\n",
      "\n",
      "The speaker concludes that extreme success is not the ultimate goal, and that it is more important to focus on finding a correct contrarian idea that is important to you, rather than trying to become more successful than 99% of people. He suggests that before pursuing success, it is important to define what success means to you, and to make sure that you are setting the right goals for yourself.\n"
     ]
    }
   ],
   "source": [
    "transcript = clean_transcript(fetch_transcript(\"https://www.youtube.com/watch?v=_ZJpU43NA0c\"))\n",
    "podcast_summary = summarize(transcript, pipeline_llama2)\n",
    "print(podcast_summary)\n",
    "with open('notes\\\\HowtoGetAheadof99ofPeople(Starting Today).txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(podcast_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
