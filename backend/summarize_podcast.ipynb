{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcript\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import os\n",
    "# Summarization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from langchain import PromptTemplate,  LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transcript_to_file(transcript_text, file_name):\n",
    "    temp_folder = 'temp'\n",
    "    file_path = os.path.join(temp_folder, file_name)\n",
    "    # Create the 'temp' directory if it doesn't exist\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(transcript_text)\n",
    "        return file_path\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def fetch_transcript(video_url):\n",
    "    try:\n",
    "        # Extract the video ID from the URL\n",
    "        video_id = video_url.split(\"v=\")[1]\n",
    "        # Fetch the transcript for the video\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        # Process the transcript data\n",
    "        text_transcript = \"\\n\".join([entry['text'] for entry in transcript])\n",
    "        return text_transcript\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript:\n",
      "\n",
      "you can use Neuroscience to hack your\n",
      "brain to self-study way faster and you\n",
      "can use AI to enhance t\n"
     ]
    }
   ],
   "source": [
    "# Define the YouTube video URL (replace with your desired video URL)\n",
    "# video_url = \"https://www.youtube.com/watch?v=13CZPWmke6A&list=WL&index=15&t=8s&ab_channel=LexFridman\"\n",
    "video_url = \"https://www.youtube.com/watch?v=ZsMJBw4faJM\" # How To Self Study FAST\n",
    "\n",
    "transcript_text = fetch_transcript(video_url)\n",
    "if transcript_text:\n",
    "    print(\"Transcript:\\n\")\n",
    "    print(transcript_text[0:100])\n",
    "    save_transcript_to_file(transcript_text, \"video_transcript.txt\")\n",
    "else:\n",
    "    print(\"Failed to fetch the transcript.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7618b36f78ac42828830f6d496b14c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "max_token_length = 1000\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", #task\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=max_token_length,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})\n",
    "template = \"\"\"\n",
    "              Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "           \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_text = transcript_text.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = llm_chain.run(transcript_text[0:1000])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you can use Neuroscience to hack your\\nbrain to self-study way faster and you\\ncan use AI to enhance those effects even\\nmore as a child I absolutely hated\\nschool have you ever experienced that\\nfeeling when you're not paying attention\\nand that a teacher calls on you for a\\nquestion and you just like don't know\\nwhat the teacher asked H so your choices\\nare either say something random or ask a\\nteacher to repeat themselves neither of\\nwhich are good choices to do but I\\nalways did well in school though I\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_text[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' • Using neuroscience to hack your brain to study faster.\\n            • Using AI to even enhance those effects.\\n            • The author hated school as a child.\\n            • Struggling to pay attention and recall information.\\n            • Feeling anxious when called on in class.\\n            • The author always did well in school despite these challenges.\\n\\nPlease provide the actual text you would like me to summarize and I will assist you.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the following is a conversation with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elias discover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>co-founder and chief scientist of open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai one of the most cited computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientists in history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>if this were then subjected to an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>appropriate course of education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>one would obtain the adult brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>thank you for listening and hope to see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>you next time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2965 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text\n",
       "0        the following is a conversation with\n",
       "1                              elias discover\n",
       "2      co-founder and chief scientist of open\n",
       "3           ai one of the most cited computer\n",
       "4                       scientists in history\n",
       "...                                       ...\n",
       "2960        if this were then subjected to an\n",
       "2961          appropriate course of education\n",
       "2962         one would obtain the adult brain\n",
       "2963  thank you for listening and hope to see\n",
       "2964                            you next time\n",
       "\n",
       "[2965 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_text_list = transcript_text.split('\\n')\n",
    "pd.DataFrame(data=transcript_text_list,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
